plot(Ps[2,], type = 'l')
hist(Ps[2,])
plot(Ps[3,], type = 'l')
hist(Ps[3,])
(max(vars[[g]][,n]) < 5)
#use Bayesian approach
N = dim(iris)[1]
G = 3
means     <- lapply(1:G, function(g) matrix(NA,nrow=4,ncol=5500))
vars      <- lapply(1:G, function(g) matrix(NA,nrow=4*4,ncol=5500))
Ps        <- matrix(NA,nrow=G, ncol=5500)
Zs        <- matrix(NA,nrow=N, ncol=5500)
mu_0      <- rep(0, 4)
sigma_0   <-  1/10*diag(4)
nu <- 6
psi <- 5*diag(4)
alpha <- 10
for (g in 1:G) {
means[[g]][,1] <- colMeans(iris[,1:4])
vars[[g]][,1]  <- 1/10*diag(4)
}
Ps[,1]   <- rep(1/G, G)
Zs[,1]  <- sample(c(1:G), N, replace = TRUE)
for (n in 2:5500){
for (g in 1:G) {
n_g = sum(Zs[,n-1]==g)
if (n_g > 0) {
sigma_inv   <- solve(matrix(vars[[g]][,n-1], nrow = 4))
normal_var  <- solve(n_g * sigma_inv + sigma_0)
normal_mu   <- normal_var %*% (n_g * sigma_inv %*% colMeans(iris[Zs[,n-1]==g,1:4])+sigma_0 %*% mu_0)
means[[g]][, n] <- rmvnorm(1, normal_mu, normal_var)
diff <- as.matrix(iris[Zs[,n-1]==g,1:4] - matrix(normal_mu, nrow = n_g, ncol = 4, byrow = TRUE))
psi_o <- t(diff) %*% (diff)
vars[[g]][, n]  <- riwish(n_g+nu, psi + psi_o)
while (max(vars[[g]][,n]) >= 5) {
vars[[g]][, n] <- riwish(n_g+nu, psi + psi_o)
}
} else {
means[[g]][, n] <-  means[[g]][, n-1]
vars[[g]][, n]  <- vars[[g]][, n-1]
}
}
#p updates
alpha_g <- alpha + tabulate(as.factor(Zs[,n-1]), G)
E <- rexp(G, rate = 1/alpha_g)
Ps[,n]<- E / sum(E)
#Z updates
probs = matrix(NA, N, G)
for (g in 1:G) {
probs[, g] = Ps[g,n]* dmvnorm(iris[,1:4], means[[g]][,n], matrix(vars[[g]][,n], nrow = 4))
}
probs = probs / rowSums(probs)
myfun <- function(x){sample(c(1:G), 1, prob = x)}
Zs[,n] = apply(probs, 1, FUN = myfun)
}
par(mfrow = c(4,2))
for (i in 1:4) {
plot(means[[1]][i, -c(1:500)], type = 'l')
hist(means[[1]][i,-c(1:500)])
}
rowMeans(means[[1]])
for (i in 1:4) {
plot(means[[2]][i, -c(1:500)], type = 'l')
hist(means[[2]][i,-c(1:500)])
}
rowMeans(means[[2]])
for (i in 1:4) {
plot(means[[3]][i, -c(1:500)], type = 'l')
hist(means[[3]][i,-c(1:500)])
}
rowMeans(means[[3]])
#use Bayesian approach
N = dim(iris)[1]
G = 3
means     <- lapply(1:G, function(g) matrix(NA,nrow=4,ncol=5500))
vars      <- lapply(1:G, function(g) matrix(NA,nrow=4*4,ncol=5500))
Ps        <- matrix(NA,nrow=G, ncol=5500)
Zs        <- matrix(NA,nrow=N, ncol=5500)
mu_0      <- rep(0, 4)
sigma_0   <-  1/10*diag(4)
nu <- 6
psi <- 2*diag(4)
alpha <- 20
for (g in 1:G) {
means[[g]][,1] <- colMeans(iris[,1:4])
vars[[g]][,1]  <- 1/10*diag(4)
}
Ps[,1]   <- rep(1/G, G)
Zs[,1]  <- sample(c(1:G), N, replace = TRUE)
for (n in 2:5500){
for (g in 1:G) {
n_g = sum(Zs[,n-1]==g)
if (n_g > 0) {
sigma_inv   <- solve(matrix(vars[[g]][,n-1], nrow = 4))
normal_var  <- solve(n_g * sigma_inv + sigma_0)
normal_mu   <- normal_var %*% (n_g * sigma_inv %*% colMeans(iris[Zs[,n-1]==g,1:4])+sigma_0 %*% mu_0)
means[[g]][, n] <- rmvnorm(1, normal_mu, normal_var)
diff <- as.matrix(iris[Zs[,n-1]==g,1:4] - matrix(normal_mu, nrow = n_g, ncol = 4, byrow = TRUE))
psi_o <- t(diff) %*% (diff)
vars[[g]][, n]  <- riwish(n_g+nu, psi + psi_o)
while (max(vars[[g]][,n]) >= 5) {
vars[[g]][, n] <- riwish(n_g+nu, psi + psi_o)
}
} else {
means[[g]][, n] <-  means[[g]][, n-1]
vars[[g]][, n]  <- vars[[g]][, n-1]
}
}
#p updates
alpha_g <- alpha + tabulate(as.factor(Zs[,n-1]), G)
E <- rexp(G, rate = 1/alpha_g)
Ps[,n]<- E / sum(E)
#Z updates
probs = matrix(NA, N, G)
for (g in 1:G) {
probs[, g] = Ps[g,n]* dmvnorm(iris[,1:4], means[[g]][,n], matrix(vars[[g]][,n], nrow = 4))
}
probs = probs / rowSums(probs)
myfun <- function(x){sample(c(1:G), 1, prob = x)}
Zs[,n] = apply(probs, 1, FUN = myfun)
}
#summary
for (i in 1:4) {
plot(means[[3]][i, -c(1:500)], type = 'l')
hist(means[[3]][i,-c(1:500)])
}
rowMeans(means[[3]])
#use Bayesian approach
N = dim(iris)[1]
G = 3
means     <- lapply(1:G, function(g) matrix(NA,nrow=4,ncol=5500))
vars      <- lapply(1:G, function(g) matrix(NA,nrow=4*4,ncol=5500))
Ps        <- matrix(NA,nrow=G, ncol=5500)
Zs        <- matrix(NA,nrow=N, ncol=5500)
mu_0      <- rep(0, 4)
sigma_0   <-  1/10*diag(4)
nu <- 6
psi <- 2*diag(4)
alpha <- 20
for (g in 1:G) {
means[[g]][,1] <- colMeans(iris[,1:4])
vars[[g]][,1]  <- diag(4)
}
Ps[,1]   <- rep(1/G, G)
Zs[,1]  <- sample(c(1:G), N, replace = TRUE)
for (n in 2:5500){
for (g in 1:G) {
n_g = sum(Zs[,n-1]==g)
sigma_inv   <- solve(matrix(vars[[g]][,n-1], nrow = 4))
normal_var  <- solve(n_g * sigma_inv + sigma_0)
normal_mu   <- normal_var %*% (n_g * sigma_inv %*% colMeans(iris[Zs[,n-1]==g,1:4])+sigma_0 %*% mu_0)
means[[g]][, n] <- rmvnorm(1, normal_mu, normal_var)
diff <- as.matrix(iris[Zs[,n-1]==g,1:4] - matrix(normal_mu, nrow = n_g, ncol = 4, byrow = TRUE))
psi_o <- t(diff) %*% (diff)
vars[[g]][, n]  <- riwish(n_g+nu, psi + psi_o)
while (max(vars[[g]][,n]) >= 5) {
vars[[g]][, n] <- riwish(n_g+nu, psi + psi_o)
}
}
#p updates
alpha_g <- alpha + tabulate(as.factor(Zs[,n-1]), G)
E <- rexp(G, rate = 1/alpha_g)
Ps[,n]<- E / sum(E)
#Z updates
probs = matrix(NA, N, G)
for (g in 1:G) {
probs[, g] = Ps[g,n]* dmvnorm(iris[,1:4], means[[g]][,n], matrix(vars[[g]][,n], nrow = 4))
}
probs = probs / rowSums(probs)
myfun <- function(x){sample(c(1:G), 1, prob = x)}
Zs[,n] = apply(probs, 1, FUN = myfun)
}
#use Bayesian approach
N = dim(iris)[1]
G = 3
means     <- lapply(1:G, function(g) matrix(NA,nrow=4,ncol=5500))
vars      <- lapply(1:G, function(g) matrix(NA,nrow=4*4,ncol=5500))
Ps        <- matrix(NA,nrow=G, ncol=5500)
Zs        <- matrix(NA,nrow=N, ncol=5500)
mu_0      <- rep(0, 4)
sigma_0   <-  1/10*diag(4)
nu <- 6
psi <- 2*diag(4)
alpha <- 20
for (g in 1:G) {
means[[g]][,1] <- colMeans(iris[,1:4])
vars[[g]][,1]  <- diag(4)
}
Ps[,1]   <- rep(1/G, G)
Zs[,1]  <- sample(c(1:G), N, replace = TRUE)
for (n in 2:5500){
for (g in 1:G) {
n_g = sum(Zs[,n-1]==g)
sigma_inv   <- solve(matrix(vars[[g]][,n-1], nrow = 4))
normal_var  <- solve(n_g * sigma_inv + sigma_0)
normal_mu   <- normal_var %*% (n_g * sigma_inv %*% colMeans(iris[Zs[,n-1]==g,1:4])+sigma_0 %*% mu_0)
means[[g]][, n] <- rmvnorm(1, normal_mu, normal_var)
diff <- as.matrix(iris[Zs[,n-1]==g,1:4] - matrix(normal_mu, nrow = n_g, ncol = 4, byrow = TRUE))
psi_o <- t(diff) %*% (diff)
vars[[g]][, n]  <- riwish(n_g+nu, psi + psi_o)
while (max(vars[[g]][,n]) >= 5) {
vars[[g]][, n] <- riwish(n_g+nu, psi + psi_o)
}
}
#p updates
alpha_g <- alpha + tabulate(as.factor(Zs[,n-1]), G)
E <- rexp(G, rate = 1/alpha_g)
Ps[,n]<- E / sum(E)
#Z updates
probs = matrix(NA, N, G)
for (g in 1:G) {
probs[, g] = Ps[g,n]* dmvnorm(iris[,1:4], means[[g]][,n], matrix(vars[[g]][,n], nrow = 4))
}
probs = probs / rowSums(probs)
myfun <- function(x){sample(c(1:G), 1, prob = x)}
Zs[,n] = apply(probs, 1, FUN = myfun)
}
#use Bayesian approach
N = dim(iris)[1]
G = 3
means     <- lapply(1:G, function(g) matrix(NA,nrow=4,ncol=5500))
vars      <- lapply(1:G, function(g) matrix(NA,nrow=4*4,ncol=5500))
Ps        <- matrix(NA,nrow=G, ncol=5500)
Zs        <- matrix(NA,nrow=N, ncol=5500)
mu_0      <- rep(0, 4)
sigma_0   <-  1/10*diag(4)
nu <- 6
psi <- 2*diag(4)
alpha <- 20
for (g in 1:G) {
means[[g]][,1] <- colMeans(iris[,1:4])
vars[[g]][,1]  <- diag(4)
}
Ps[,1]   <- rep(1/G, G)
Zs[,1]  <- sample(c(1:G), N, replace = TRUE)
for (n in 2:5500){
for (g in 1:G) {
n_g = sum(Zs[,n-1]==g)
if (n_g > 0) {
sigma_inv   <- solve(matrix(vars[[g]][,n-1], nrow = 4))
normal_var  <- solve(n_g * sigma_inv + sigma_0)
normal_mu   <- normal_var %*% (n_g * sigma_inv %*% colMeans(iris[Zs[,n-1]==g,1:4])+sigma_0 %*% mu_0)
means[[g]][, n] <- rmvnorm(1, normal_mu, normal_var)
diff <- as.matrix(iris[Zs[,n-1]==g,1:4] - matrix(normal_mu, nrow = n_g, ncol = 4, byrow = TRUE))
psi_o <- t(diff) %*% (diff)
vars[[g]][, n]  <- riwish(n_g+nu, psi + psi_o)
while (max(vars[[g]][,n]) >= 5) {
vars[[g]][, n] <- riwish(n_g+nu, psi + psi_o)
}
} else {
means[[g]][, n] <-  means[[g]][, n-1]
vars[[g]][, n]  <- vars[[g]][, n-1]
}
}
#p updates
alpha_g <- alpha + tabulate(as.factor(Zs[,n-1]), G)
E <- rexp(G, rate = 1/alpha_g)
Ps[,n]<- E / sum(E)
#Z updates
probs = matrix(NA, N, G)
for (g in 1:G) {
probs[, g] = Ps[g,n]* dmvnorm(iris[,1:4], means[[g]][,n], matrix(vars[[g]][,n], nrow = 4))
}
probs = probs / rowSums(probs)
myfun <- function(x){sample(c(1:G), 1, prob = x)}
Zs[,n] = apply(probs, 1, FUN = myfun)
}
#summary
par(mfrow = c(4,2))
for (i in 1:4) {
plot(means[[1]][i, -c(1:500)], type = 'l')
hist(means[[1]][i,-c(1:500)])
}
rowMeans(means[[1]])
for (i in 1:4) {
plot(means[[2]][i, -c(1:500)], type = 'l')
hist(means[[2]][i,-c(1:500)])
}
rowMeans(means[[2]])
for (i in 1:4) {
plot(means[[3]][i, -c(1:500)], type = 'l')
hist(means[[3]][i,-c(1:500)])
}
rowMeans(means[[3]])
matrix(vars[[g]][,n], nrow = 4)
#use Bayesian approach
N = dim(iris)[1]
G = 3
means     <- lapply(1:G, function(g) matrix(NA,nrow=4,ncol=5500))
vars      <- lapply(1:G, function(g) matrix(NA,nrow=4*4,ncol=5500))
Ps        <- matrix(NA,nrow=G, ncol=5500)
Zs        <- matrix(NA,nrow=N, ncol=5500)
mu_0      <- rep(0, 4)
sigma_0   <-  1/10*diag(4)
nu <- 6
psi <- 2*diag(4)
alpha <- 50
for (g in 1:G) {
means[[g]][,1] <- colMeans(iris[,1:4])
vars[[g]][,1]  <- diag(4)
}
Ps[,1]   <- rep(1/G, G)
Zs[,1]  <- sample(c(1:G), N, replace = TRUE)
for (n in 2:5500){
for (g in 1:G) {
n_g = sum(Zs[,n-1]==g)
if (n_g > 0) {
sigma_inv   <- solve(matrix(vars[[g]][,n-1], nrow = 4))
normal_var  <- solve(n_g * sigma_inv + sigma_0)
normal_mu   <- normal_var %*% (n_g * sigma_inv %*% colMeans(iris[Zs[,n-1]==g,1:4])+sigma_0 %*% mu_0)
means[[g]][, n] <- rmvnorm(1, normal_mu, normal_var)
diff <- as.matrix(iris[Zs[,n-1]==g,1:4] - matrix(normal_mu, nrow = n_g, ncol = 4, byrow = TRUE))
psi_o <- t(diff) %*% (diff)
vars[[g]][, n]  <- riwish(n_g+nu, psi + psi_o)
while (max(vars[[g]][,n]) >= 5) {
vars[[g]][, n] <- riwish(n_g+nu, psi + psi_o)
}
} else {
means[[g]][, n] <-  means[[g]][, n-1]
vars[[g]][, n]  <- vars[[g]][, n-1]
}
}
#p updates
alpha_g <- alpha + tabulate(as.factor(Zs[,n-1]), G)
E <- rexp(G, rate = 1/alpha_g)
Ps[,n]<- E / sum(E)
#Z updates
probs = matrix(NA, N, G)
for (g in 1:G) {
probs[, g] = Ps[g,n]* dmvnorm(iris[,1:4], means[[g]][,n], matrix(vars[[g]][,n], nrow = 4))
}
probs = probs / rowSums(probs)
myfun <- function(x){sample(c(1:G), 1, prob = x)}
Zs[,n] = apply(probs, 1, FUN = myfun)
}
#summary
par(mfrow = c(4,2))
for (i in 1:4) {
plot(means[[1]][i, -c(1:500)], type = 'l')
hist(means[[1]][i,-c(1:500)])
}
rowMeans(means[[1]])
for (i in 1:4) {
plot(means[[2]][i, -c(1:500)], type = 'l')
hist(means[[2]][i,-c(1:500)])
}
rowMeans(means[[2]])
#use Bayesian approach
N = dim(iris)[1]
G = 3
means     <- lapply(1:G, function(g) matrix(NA,nrow=4,ncol=5500))
vars      <- lapply(1:G, function(g) matrix(NA,nrow=4*4,ncol=5500))
Ps        <- matrix(NA,nrow=G, ncol=5500)
Zs        <- matrix(NA,nrow=N, ncol=5500)
mu_0      <- rep(0, 4)
sigma_0   <-  1/10*diag(4)
nu <- 6
psi <- 2*diag(4)
alpha <- 5
for (g in 1:G) {
means[[g]][,1] <- colMeans(iris[,1:4])
vars[[g]][,1]  <- diag(4)
}
Ps[,1]   <- rep(1/G, G)
Zs[,1]  <- sample(c(1:G), N, replace = TRUE)
for (n in 2:5500){
for (g in 1:G) {
n_g = sum(Zs[,n-1]==g)
if (n_g > 0) {
sigma_inv   <- solve(matrix(vars[[g]][,n-1], nrow = 4))
normal_var  <- solve(n_g * sigma_inv + sigma_0)
normal_mu   <- normal_var %*% (n_g * sigma_inv %*% colMeans(iris[Zs[,n-1]==g,1:4])+sigma_0 %*% mu_0)
means[[g]][, n] <- rmvnorm(1, normal_mu, normal_var)
diff <- as.matrix(iris[Zs[,n-1]==g,1:4] - matrix(normal_mu, nrow = n_g, ncol = 4, byrow = TRUE))
psi_o <- t(diff) %*% (diff)
vars[[g]][, n]  <- riwish(n_g+nu, psi + psi_o)
while (max(vars[[g]][,n]) >= 5) {
vars[[g]][, n] <- riwish(n_g+nu, psi + psi_o)
}
} else {
means[[g]][, n] <-  means[[g]][, n-1]
vars[[g]][, n]  <- vars[[g]][, n-1]
}
}
#p updates
alpha_g <- alpha + tabulate(as.factor(Zs[,n-1]), G)
E <- rexp(G, rate = 1/alpha_g)
Ps[,n]<- E / sum(E)
#Z updates
probs = matrix(NA, N, G)
for (g in 1:G) {
probs[, g] = Ps[g,n]* dmvnorm(iris[,1:4], means[[g]][,n], matrix(vars[[g]][,n], nrow = 4))
}
probs = probs / rowSums(probs)
myfun <- function(x){sample(c(1:G), 1, prob = x)}
Zs[,n] = apply(probs, 1, FUN = myfun)
}
for (i in 1:4) {
plot(means[[2]][i, -c(1:500)], type = 'l')
hist(means[[2]][i,-c(1:500)])
}
rowMeans(means[[2]])
for (i in 1:4) {
plot(means[[3]][i, -c(1:500)], type = 'l')
hist(means[[3]][i,-c(1:500)])
}
rowMeans(means[[3]])
library(LaplacesDemon)
dmvc(1, rnorm(3), matrix(0, 3, 3))
dmvc(1, rnorm(3), matrix(1, 3, 3))
NULL
NULL+3
library(devtools)
setwd("/Users/bomin8319/Desktop/MulticastNetwork/pkg/R")
document()
check()
install()
library(MulticastNetwork)
#load our Montgomery county email data
load("/Users/bomin8319/Box/gainlab_example/Bomin/Montgomery.RData")
names(Montgomery)
#data including sender a_d, reciever vector r_d, timestamp t_d
edge = Montgomery$edge
head(edge)
#covariates affecting "who sends to whom"
X = Montgomery$X
head(X[100, 1, , ])
X = X[,,,c(1:5)]    #use few covariates for this application
#covariates affecting "when to send"
Y = Montgomery$Y
head(Y[100, , ])
Y = Y[,,c(1:5)]    #use few covariates for this application
P = dim(X)[4]
Q = dim(Y)[3]
#run inference to estimate beta, eta, u, and sigma2
prior.beta = list(mean = rep(0, P), var = 2*diag(P))
prior.eta = list(mean = rep(0, Q), var = 2*diag(Q))
prior.sigma2 = list(a = 2, b = 1)
outer = 500
inner = c(1, 1, 1)
burn = 0
#this initial values are my results after convergence
initialval = list()
initialval$beta = c(-3.548488159, -0.108898033,  0.086928281,  0.274102964,  0.029273815)
initialval$eta = c(7.38197540,  0.12883606, -1.07065227, -0.20698218, -0.05894448)
initialval$sigma2 = 14.09288
initialval$u = lapply(1:dim(X)[1], function(d) matrix(0, dim(X)[2], dim(X)[2]))
#run infernece
Montgomery_infer = Inference(edge, X, Y, outer, inner, burn, prior.beta, prior.eta, prior.sigma2, initialval = initialval,
proposal.var = c(0.0001, 0.001, 0.1), timeunit = 3600, lasttime = Montgomery$lasttime, timedist = "lognormal")
names(Montgomery_infer)
# check convergence
plot(Montgomery_infer$loglike, type = 'l')
# generate data from the model estimates
Montgomery_PPC = PPC(length(edge), beta = colMeans(Montgomery_infer$beta), eta = colMeans(Montgomery_infer$eta),
sigma2 = mean(Montgomery_infer$sigma2), X, Y, timeunit = 3600, u = Montgomery_infer$u, timedist = "lognormal")
Montgomery_PPC
email[min(trim-1), 21] - initialtime
Montgomery$lasttime
set.seed(1)
missing = list()
missing[[1]] = matrix(0, nrow = dim(Y)[1], 1)
missing[[1]][sample(1:dim(Y)[1], 62, replace = FALSE), ] = 1
missing[[2]] = matrix(0, nrow = dim(Y)[1], A)
missing[[2]][sample(1:(dim(Y)[1]*A), 1118, replace = FALSE)] = 1
missing[[3]] = matrix(0, nrow = dim(Y)[1], 1)
missing[[3]][sample(1:dim(Y)[1], 62, replace = FALSE), ] = 1
A = dim(Y)[3]
A = dim(Y)[2]
A
set.seed(1)
missing = list()
missing[[1]] = matrix(0, nrow = dim(Y)[1], 1)
missing[[1]][sample(1:dim(Y)[1], 62, replace = FALSE), ] = 1
missing[[2]] = matrix(0, nrow = dim(Y)[1], A)
missing[[2]][sample(1:(dim(Y)[1]*A), 1118, replace = FALSE)] = 1
missing[[3]] = matrix(0, nrow = dim(Y)[1], 1)
missing[[3]][sample(1:dim(Y)[1], 62, replace = FALSE), ] = 1
missing
missing[[1]]
#will generate 50 predictions (iterate two steps: imputation -> inference)
Montgomery_PPE = PPE(edge, missing, X, Y, 50, c(5,5,1), 0, prior.beta, prior.eta, prior.sigma2,
initial = initial, proposal.var = c(0.0001, 0.001, 0.1), timeunit = 3600,
lasttime = Montgomery$lasttime, MHprop.var = 0.1, timedist = "lognormal")
# prediction experiment
# hide 10% of senders, receivers, and timestamps
set.seed(1)
missing = list()
#missingness of senders
missing[[1]] = matrix(0, nrow = dim(Y)[1], 1)
missing[[1]][sample(1:dim(Y)[1], 62, replace = FALSE), ] = 1
#missingness of receivers
missing[[2]] = matrix(0, nrow = dim(Y)[1], A)
missing[[2]][sample(1:(dim(Y)[1]*A), 1118, replace = FALSE)] = 1
#missingness of timestamps
missing[[3]] = matrix(0, nrow = dim(Y)[1], 1)
missing[[3]][sample(1:dim(Y)[1], 62, replace = FALSE), ] = 1
# use parameter estimates as initial values
initial = list()
initial$beta = colMeans(Montgomery_infer$beta)
initial$eta =  colMeans(Montgomery_infer$eta)
initial$u = Montgomery_infer$u
initial$sigma2 = mean(Montgomery_infer$sigma2)
#will generate 50 predictions (iterate two steps: imputation -> inference)
Montgomery_PPE = PPE(edge, missing, X, Y, 50, c(5,5,1), 0, prior.beta, prior.eta, prior.sigma2,
initial = initial, proposal.var = c(0.0001, 0.001, 0.1), timeunit = 3600,
lasttime = Montgomery$lasttime, MHprop.var = 0.1, timedist = "lognormal")
#will generate 10 predictions (iterate two steps: imputation -> inference)
Montgomery_PPE = PPE(edge, missing, X, Y, 10, c(5,5,1), 0, prior.beta, prior.eta, prior.sigma2,
initial = initial, proposal.var = c(0.0001, 0.001, 0.1), timeunit = 3600,
lasttime = Montgomery$lasttime, MHprop.var = 0.1, timedist = "lognormal")
Montgomery_PPE
